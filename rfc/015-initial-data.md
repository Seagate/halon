# RFC: Initial Data

## Introduction

In order for Halon to operate correctly, it must be initially told a number of
'facts' about the system it is to manage. This document describes such 'facts',
and the process by which we may inject them into Halon.

## Purpose

Whilst the intention is that Halon should auto-discover as much information as
possible through its own network of sensors, it is not possible at present to
do this for everything. At first boot, in system updates, and potentially in
other situations it must be possible to inject data into Halon's resource graph
directly.

## Constraints

* Whilst we are principally concerned with injecting *initial* data, we must
also consider future requirements for upgrading the system. In such a case, we
have the additional complication of having to merge the new configuration with
the existing data in the resource graph.

* We are unlikely to correctly identify the full list of data required at first
try; as such, whatever mechanism we put in place must be easy to update as we
identify new data to add in.

* Data are to be initially generated by the provisioner; we should consider how
it is easiest for them to provide such data.

* The existence of these initial data in a location other than the Halon resource
graph presents a potential confusion in terms of authority. Halon should include
means to prevent anything other than a deliberate update to initial
configuration overriding the data stored in its resoure graph.

## Conflicts/Relations

* We already have the ability to inject certain data into the resource graph in
the form of service configuration. These are different to the initial data in
that they are explicitly scoped to one part of the system rather than the
system as a whole, and that they are delineated as such in the resource graph,
making the story for updating them much simpler. However, from the perspective
of the user, there is little to distinguish these, and as such we should aim
to make it possible to subsume service configuration into initial data whilst
retaining the ability to update it independently later.

* As yet unimplemented, but we will need some form of configuration for the
rules in the form of parameter tuning; the ability to toggle rules on and off,
set timeouts and reactions etc. This may be seen as service configuration for
the RC, if the RC were a service, and as the same advantages; it is explicitly
scoped and may thus be upgraded much more easily. Again, we may wish to allow
the initial rule parameters to be subsumed into (a section of) the initial data.

## Overview

### List of data

We will require initial data to be injected for the following purposes:

- Defining the list of nodes in the cluster, and their roles
  - Node identity should be in the form of a hostname which is fixed over the
    lifetime of the system.
- Network interface(s) to be used on each node
- Drives to be used on each node
- Defining the set of client nodes
- Non-discoverable aspects of network topology:
  - BMC address
- Global parameters for Mero configuration, such as:
  - Pool width
  - n, k, s

We could optionally add the following if we wish to subsume service
configuration:

- For each node, which services to run, and the corresponding configuration

We could optionally add the following if we wish to subsume starting the
tracking station:

- List of tracking station nodes
- Rule parameter configuration

### Updates

Various items may plausibly change during the lifetime of a running system. The
complexity of handling these depends on whether such an update is a simple
replacement, or whether it represents an addition/deletion; and whether the
data may be updated inside Halon or not.

In general, the process should be relatively simple where either data are
replaced only 'as a whole', or where Halon does not update those data:
- If data are replaced only 'as a whole', we may assume that the user pushing
an update has given consideration to this replacement, and that the pushed data
should take precedence over those in the RG.
- If the data are not updated in Halon, then updates from outside may be
considered authoritative, and we need not worry.

However, the concern exists where data may be updated 'in part' (e.g. added to
or deleted from), and where those data may also be modified by Halon. In this
scenario, we have the classic merge problem; the external data source has been
modified from an original version, but the reflection up that inside Halon has
since been updated, and we wish to apply the external change without overwriting
the internal changes. We see three possible strategies here:

1. Treat the user-provided data as authoritative. This is the simplest of
strategies for Halon, but requires that the external user be responsible for
verifying that they are up to date with Halon before pushing changes.
2. Allow full diff/merge. This is the most powerful approach, but hard to
implement, and raises questions about what we do if we cannot successfully
merge.
3. Allow SET/PUT/DELETE semantics Ã  la REST. This is probably the best approach;
it requires that we can identify the path to each object, but then allows us to
write into particular parts of the tree. A configuration update then becomes an
operation on a particular part of configuration.

## Startup sequence

Provision of initial data is specific to the Castor usage of Halon, and as such
we do not wish to place it in the startup section, which should be generic
to all potential clients. Instead, we propose the following start-up sequence:

1. Start all `halond` instances.
2. Bootstrap Halon tracking station.
3. (New step) Inject initial data.
4. Bootstrap all satellite nodes.
5. Start desired services.

However, to simplify things for the client, we propose adding a simplified
`bootstrap` command which would be responsible for steps 2-5, and so the
revised bootstrap process would be:

1. Start all `halond` instances.
2. Bootstrap cluster with initial data.

Since initial injection (and certainly any subsequent updates) happen after the
RC has started, we assert that handling such updates should be done by a rule,
as with any other scenario.

## Configuration schema

Without identifying a particular format for the expression of initial data, we
propose a schema which satisfies the constraints of:

1. Isolating those parts of the configuration which are already covered by
service configuration, existing boostrap steps, or will be covered by rule
parameter loading.

2. Providing identifying paths to parts of the configuration which we might
wish to update independently.

We describe this in a pseudo-REST format, with the final children collapsed
into a map-like syntax.

```
/
/racks
/racks/<rack>/enclosures
/racks/<rack>/enclosures/<enclosure>/bmc/{addr=<bmcaddr>,user=<bmcuser>,password=<bmcpass>}
/racks/<rack>/enclosures/<enclosure>/hosts
/racks/<rack>/enclosures/<enclosure>/hosts/<host>
/racks/<rack>/enclosures/<enclosure>/hosts/<host>/interfaces
/racks/<rack>/enclosures/<enclosure>/hosts/<host>/interfaces/<loopbackif>/{net=loopback}
/racks/<rack>/enclosures/<enclosure>/hosts/<host>/interfaces/<dataif>/{net=data}
/racks/<rack>/enclosures/<enclosure>/hosts/<host>/{mem=<memlimit>, nr_cpu=<nr_cpu>, ...}

/mero
/mero/globals/{n=<n>, k=<k>, pw=<pw>, ...}
/mero/servers
/mero/servers/<host>
/mero/servers/<host>/devices
/mero/servers/<host>/devices/<device>/{path=<path>, size=<size>, bsize=<bsize>, ...}
/mero/servers/<host>/services
/mero/servers/<host>/services/<m0service>/endpoints
/mero/servers/<host>/services/<m0service>/{...}
/mero/servers/<host>/{mem_as=<memlimit>, mem_rss=<memlimit>, ...}

/halon
/halon/nodes
/halon/nodes/<node>
/halon/nodes/<node>/services
/halon/nodes/<node>/services/<haservice>
/halon/nodes/<node>/services/<haservice>/{...}
/halon/stations
/halon/rules
```

### Identifiers

Various entities in the above example require unique identifiers. We suggest the
following:

* `<rack>` should be identified by a simple integer.
* `<enclosure>` should be identified by an integer representing position in the
rack (enumerated from top down.)
* `<host>` should be the FQDN of the host.
* `<node>` should be the cloud haskell `NodeId`.
* `<if>` should be the MAC address of the interface.
* `<device>` should be the WWN of the device.
* `<m0service>` should be the Mero service name, as defined in `conf/schema.h`.
* `<haservice>` should be the service name, as used in the RG.

### Update format

The update format should consist of a set of triples, along with a version
number:

`(VERSION, [(OP, PATH, DATA)])`,

where `OP` is one of `SET`, `INSERT`, or `DELETE`; `PATH` identifies a subtree
as indicated above, and `DATA` is some appropriate representation of the data
contained in that subtree.

`VERSION` is a counter designed to make certain that old data cannot be pushed
into the RG and overwrite data which it itself has modified. Halon should store
the most recent version number and reject any attempt to insert data with the
same or lower version. To support this. Halon should also offer the ability to
print the most recent version number it is aware of.





